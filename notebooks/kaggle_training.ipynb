{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "1886846a",
            "metadata": {},
            "source": [
                "# üåå x.titan: Autonomous Trading Brain - Kaggle Training\n",
                "\n",
                "**Version**: 2026.1.2 (GPU-Optimized)\n",
                "**Source**: GitHub ‚Üí https://github.com/planetazul3/x.titan\n",
                "\n",
                "## ‚öôÔ∏è Requirements\n",
                "1. **GPU Accelerator**: Enable in Kaggle Settings (T4 or P100 recommended)\n",
                "2. **Kaggle Secrets**: Add `DERIV_API_TOKEN` for data download\n",
                "3. **Internet**: Enable for GitHub clone + pip install"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e62abd14",
            "metadata": {},
            "source": [
                "## 1. Clone Repository from GitHub"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "eb785416",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "from pathlib import Path\n",
                "\n",
                "REPO_URL = \"https://github.com/planetazul3/x.titan.git\"\n",
                "WORKING_DIR = Path(\"/kaggle/working/x.titan\")\n",
                "\n",
                "if not WORKING_DIR.exists():\n",
                "    print(\"üì• Cloning x.titan from GitHub...\")\n",
                "    !git clone --depth 1 {REPO_URL} {WORKING_DIR}\n",
                "else:\n",
                "    print(\"‚úÖ Repository already exists\")\n",
                "\n",
                "os.chdir(WORKING_DIR)\n",
                "print(f\"üìÇ Working directory: {os.getcwd()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "0909b956",
            "metadata": {},
            "source": [
                "## 2. TA-Lib Installation (C Library)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "09b7a6fe",
            "metadata": {},
            "outputs": [],
            "source": [
                "if not os.path.exists('/usr/include/ta-lib/ta_defs.h'):\n",
                "    print(\"üì¶ Installing TA-Lib...\")\n",
                "    !apt-get update -qq && apt-get install -y -qq build-essential wget\n",
                "    !wget -q http://prdownloads.sourceforge.net/ta-lib/ta-lib-0.4.0-src.tar.gz\n",
                "    !tar -xzf ta-lib-0.4.0-src.tar.gz\n",
                "    os.chdir('ta-lib')\n",
                "    !./configure --prefix=/usr > /dev/null && make -j4 > /dev/null && make install > /dev/null\n",
                "    os.chdir('..')\n",
                "    !rm -rf ta-lib ta-lib-0.4.0-src.tar.gz\n",
                "    print(\"‚úÖ TA-Lib compiled\")\n",
                "else:\n",
                "    print(\"‚úÖ TA-Lib already installed\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "eba53fe1",
            "metadata": {},
            "source": [
                "## 3. Python Dependencies"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c748e3df",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"üì• Installing Python packages...\")\n",
                "!pip install -q TA-Lib pandas numpy torch tqdm pydantic pydantic-settings python-dotenv pyarrow\n",
                "!pip install -q -e ./python-deriv-api 2>/dev/null || pip install -q git+https://github.com/planetazul3/python-deriv-api.git\n",
                "print(\"‚úÖ Dependencies installed\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "da839111",
            "metadata": {},
            "source": [
                "## 4. Environment Configuration (API Key via Kaggle Secrets)\n",
                "\n",
                "**‚ö†Ô∏è IMPORTANT**: Add your Deriv API token in Kaggle:\n",
                "1. Click **Add-ons** ‚Üí **Secrets**\n",
                "2. Add key: `DERIV_API_TOKEN` with your token value"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6161f045",
            "metadata": {},
            "outputs": [],
            "source": [
                "from kaggle_secrets import UserSecretsClient\n",
                "\n",
                "# Load API token from Kaggle secrets\n",
                "try:\n",
                "    secrets = UserSecretsClient()\n",
                "    DERIV_API_TOKEN = secrets.get_secret(\"DERIV_API_TOKEN\")\n",
                "    print(\"‚úÖ DERIV_API_TOKEN loaded from Kaggle secrets\")\n",
                "except Exception as e:\n",
                "    print(f\"‚ö†Ô∏è Could not load secret: {e}\")\n",
                "    DERIV_API_TOKEN = \"\"  # Will fail on data download\n",
                "\n",
                "# Create .env file with all configuration\n",
                "env_content = f'''# x.titan Configuration (Generated by Kaggle Notebook)\n",
                "ENVIRONMENT=test\n",
                "DERIV_API_TOKEN={DERIV_API_TOKEN}\n",
                "DERIV_APP_ID=1089\n",
                "\n",
                "# Trading\n",
                "TRADING__SYMBOL=R_100\n",
                "TRADING__STAKE_AMOUNT=10.0\n",
                "\n",
                "# Probability Thresholds\n",
                "THRESHOLDS__CONFIDENCE_THRESHOLD_HIGH=0.80\n",
                "THRESHOLDS__LEARNING_THRESHOLD_MAX=0.70\n",
                "THRESHOLDS__LEARNING_THRESHOLD_MIN=0.50\n",
                "\n",
                "# TFT Hyperparameters (GPU Optimized)\n",
                "HYPERPARAMS__USE_TFT=True\n",
                "HYPERPARAMS__LEARNING_RATE=0.0007\n",
                "HYPERPARAMS__BATCH_SIZE=128\n",
                "HYPERPARAMS__LSTM_HIDDEN_SIZE=256\n",
                "HYPERPARAMS__CNN_FILTERS=128\n",
                "HYPERPARAMS__LATENT_DIM=64\n",
                "HYPERPARAMS__DROPOUT_RATE=0.2\n",
                "HYPERPARAMS__EPOCHS=30\n",
                "\n",
                "# Data Shapes\n",
                "DATA_SHAPES__SEQUENCE_LENGTH_TICKS=1000\n",
                "DATA_SHAPES__SEQUENCE_LENGTH_CANDLES=200\n",
                "DATA_SHAPES__WARMUP_STEPS=50\n",
                "'''\n",
                "\n",
                "with open('.env', 'w') as f:\n",
                "    f.write(env_content)\n",
                "print(\"‚úÖ .env file created\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "8c9bfad4",
            "metadata": {},
            "source": [
                "## 5. GPU Detection & Optimization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "86fb47fc",
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "\n",
                "print(\"=\" * 50)\n",
                "print(\"GPU DETECTION\")\n",
                "print(\"=\" * 50)\n",
                "\n",
                "if torch.cuda.is_available():\n",
                "    gpu_name = torch.cuda.get_device_name(0)\n",
                "    gpu_mem = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
                "    print(f\"‚úÖ GPU: {gpu_name}\")\n",
                "    print(f\"   VRAM: {gpu_mem:.1f} GB\")\n",
                "    \n",
                "    # Optimize for available VRAM\n",
                "    if gpu_mem >= 15:  # T4/P100 with 16GB\n",
                "        os.environ['HYPERPARAMS__BATCH_SIZE'] = '256'\n",
                "        print(\"   Batch size: 256 (high VRAM)\")\n",
                "    else:\n",
                "        os.environ['HYPERPARAMS__BATCH_SIZE'] = '64'\n",
                "        print(\"   Batch size: 64 (limited VRAM)\")\n",
                "    \n",
                "    !nvidia-smi\n",
                "else:\n",
                "    print(\"‚ö†Ô∏è NO GPU DETECTED - Training will be very slow!\")\n",
                "    os.environ['HYPERPARAMS__BATCH_SIZE'] = '16'"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "513601ba",
            "metadata": {},
            "source": [
                "## 6. Data Download (12 Months)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "119ba182",
            "metadata": {},
            "outputs": [],
            "source": [
                "DATA_PATH = Path('./data_cache')\n",
                "\n",
                "# Check if data already exists\n",
                "existing_files = list(DATA_PATH.glob('**/ticks/*.parquet')) if DATA_PATH.exists() else []\n",
                "\n",
                "if len(existing_files) >= 6:\n",
                "    print(f\"‚úÖ Found {len(existing_files)} tick files - skipping download\")\n",
                "else:\n",
                "    print(\"üì° Downloading 12 months of historical data...\")\n",
                "    print(\"   (This takes 10-15 minutes)\")\n",
                "    !python scripts/download_data.py --months 12 --symbol R_100 --output data_cache"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "09fefdf3",
            "metadata": {},
            "source": [
                "## 7. Training Pipeline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "de7646a2",
            "metadata": {},
            "outputs": [],
            "source": [
                "import time\n",
                "\n",
                "# Clean previous runs\n",
                "!rm -rf checkpoints/*.pt 2>/dev/null\n",
                "!rm -rf logs/tensorboard/* 2>/dev/null\n",
                "\n",
                "print(\"üöÄ STARTING TRAINING\")\n",
                "print(\"=\" * 50)\n",
                "start_time = time.time()\n",
                "\n",
                "# Execute training with GPU optimizations\n",
                "# - pin_memory=True for faster CPU‚ÜíGPU transfer\n",
                "# - num_workers auto-adjusted based on CPU count\n",
                "!python scripts/train.py \\\n",
                "    --data-path data_cache \\\n",
                "    --epochs 30 \\\n",
                "    --checkpoint-dir checkpoints\n",
                "\n",
                "elapsed = time.time() - start_time\n",
                "print(f\"\\n‚è±Ô∏è Training completed in {elapsed/60:.1f} minutes\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c85052ef",
            "metadata": {},
            "source": [
                "## 8. Verify & Export Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "299facf9",
            "metadata": {},
            "outputs": [],
            "source": [
                "import shutil\n",
                "from datetime import datetime\n",
                "\n",
                "# Verify checkpoint\n",
                "best_model = Path('checkpoints/best_model.pt')\n",
                "if best_model.exists():\n",
                "    size_mb = best_model.stat().st_size / 1e6\n",
                "    print(f\"‚úÖ best_model.pt: {size_mb:.1f} MB\")\n",
                "    \n",
                "    # Validate checkpoint\n",
                "    !python tools/verify_checkpoint.py --checkpoint checkpoints/best_model.pt\n",
                "else:\n",
                "    print(\"‚ùå No checkpoint found!\")\n",
                "\n",
                "# Create downloadable bundle\n",
                "ts = datetime.now().strftime('%Y%m%d_%H%M')\n",
                "bundle = f'xtitan_model_{ts}'\n",
                "shutil.make_archive(bundle, 'zip', root_dir='.', base_dir='checkpoints')\n",
                "print(f\"\\nüì¶ Download: {bundle}.zip from Output panel\")"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
