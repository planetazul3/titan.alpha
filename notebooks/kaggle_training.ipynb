{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Autonomous Trading Brain - Kaggle Training Pipeline\n",
                "\n",
                "This notebook sets up the environment, installs dependencies (including TA-Lib and custom Deriv API), prepares the data (full scratch download), and runs the training loop on GPU."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Environment Setup & TA-Lib Installation\n",
                "Compiling TA-Lib C-library (required for technical indicators)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import sys\n",
                "\n",
                "# Install system build tools\n",
                "!apt-get update > /dev/null\n",
                "!apt-get install -y build-essential > /dev/null\n",
                "\n",
                "# Download and compile TA-Lib\n",
                "if not os.path.exists('/usr/lib/libta_lib.so'):\n",
                "    print(\"Downloading TA-Lib source...\")\n",
                "    !wget -q http://prdownloads.sourceforge.net/ta-lib/ta-lib-0.4.0-src.tar.gz\n",
                "    !tar -xzf ta-lib-0.4.0-src.tar.gz\n",
                "    \n",
                "    print(\"Compiling TA-Lib (this takes ~2 mins)...\")\n",
                "    os.chdir('ta-lib')\n",
                "    !./configure --prefix=/usr > /dev/null\n",
                "    !make > /dev/null\n",
                "    !make install > /dev/null\n",
                "    os.chdir('..')\n",
                "    !rm -rf ta-lib ta-lib-0.4.0-src.tar.gz\n",
                "    print(\"TA-Lib installed successfully!\")\n",
                "else:\n",
                "    print(\"TA-Lib already installed.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Project Setup\n",
                "Copying code from Input to Working directory to allow execution and modification."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import shutil\n",
                "from pathlib import Path\n",
                "\n",
                "# CONFIG: Change this to match your uploaded dataset name\n",
                "INPUT_DIR = Path('/kaggle/input/xtitan-project/xtitan') \n",
                "WORKING_DIR = Path('/kaggle/working/xtitan')\n",
                "\n",
                "if not WORKING_DIR.exists():\n",
                "    print(f\"Copying project from {INPUT_DIR} to {WORKING_DIR}...\")\n",
                "    # Copy ignoring git/venv/cache if they exist\n",
                "    shutil.copytree(INPUT_DIR, WORKING_DIR, \n",
                "                    ignore=shutil.ignore_patterns('venv', '__pycache__', '.git', '*.optimize', 'data_cache'))\n",
                "    print(\"Project setup complete.\")\n",
                "else:\n",
                "    print(\"Project already in working directory.\")\n",
                "\n",
                "os.chdir(WORKING_DIR)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Install Python Dependencies\n",
                "Installing requirements and custom API."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install TA-Lib\n",
                "!pip install -r requirements.txt\n",
                "\n",
                "# CORE: Install local custom Deriv API\n",
                "print(\"Installing custom python-deriv-api...\")\n",
                "!pip install ./python-deriv-api"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Configuration\n",
                "Edit the cell below to configure your training parameters. \n",
                "**Run this cell to save the `.env` file.**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%writefile .env\n",
                "TRADING__SYMBOL=R_100\n",
                "TRADING__STAKE_AMOUNT=10.0\n",
                "\n",
                "# Probability Thresholds\n",
                "THRESHOLDS__CONFIDENCE_THRESHOLD_HIGH=0.65\n",
                "THRESHOLDS__LEARNING_THRESHOLD_MIN=0.45\n",
                "THRESHOLDS__LEARNING_THRESHOLD_MAX=0.60\n",
                "\n",
                "# Model Hyperparameters\n",
                "HYPERPARAMS__LEARNING_RATE=0.0005\n",
                "HYPERPARAMS__BATCH_SIZE=64\n",
                "HYPERPARAMS__LSTM_HIDDEN_SIZE=128\n",
                "HYPERPARAMS__CNN_FILTERS=64\n",
                "HYPERPARAMS__LATENT_DIM=32\n",
                "\n",
                "# Data Shapes\n",
                "DATA_SHAPES__SEQUENCE_LENGTH_TICKS=60\n",
                "DATA_SHAPES__SEQUENCE_LENGTH_CANDLES=60\n",
                "\n",
                "# Optional: Set API Token here directly, OR use Kaggle Secrets (see next cell)\n",
                "# DERIV_API_TOKEN=your_token_here"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.1 Load Secrets (Optional)\n",
                "If you have set `DERIV_API_TOKEN` in Kaggle Secrets (Add-ons -> Secrets), this block will append it to the configuration securely."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from kaggle_secrets import UserSecretsClient\n",
                "\n",
                "try:\n",
                "    user_secrets = UserSecretsClient()\n",
                "    api_token = user_secrets.get_secret(\"DERIV_API_TOKEN\")\n",
                "    \n",
                "    with open(\".env\", \"a\") as f:\n",
                "        f.write(f\"\\nDERIV_API_TOKEN={api_token}\\n\")\n",
                "    print(\"✅ Loaded DERIV_API_TOKEN from Kaggle Secrets and appended to .env\")\n",
                "except Exception:\n",
                "    print(\"ℹ️ No Kaggle Secret 'DERIV_API_TOKEN' found. (Ignore this if you set it manually above)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Data Preparation (Fresh Download)\n",
                "Downloading 12 months of historical data from scratch. Previous data is cleared to ensure integrity."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import shutil\n",
                "from pathlib import Path\n",
                "\n",
                "DATA_DIR = Path('data_cache')\n",
                "\n",
                "# CLEAN START: Remove existing data cache if any\n",
                "if DATA_DIR.exists():\n",
                "    print(\"Cleaning existing data cache...\")\n",
                "    shutil.rmtree(DATA_DIR)\n",
                "\n",
                "print(\"Downloading 12 months of data (This may take a while)...\")\n",
                "# Force download with --no-resume\n",
                "!python scripts/download_data.py --months 12 --symbol R_100 --output data_cache --no-resume"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. System Validation\n",
                "Running data integrity checks and pre-flight validation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"--- Final Integrity Check ---\")\n",
                "!python scripts/final_integrity_check.py\n",
                "\n",
                "print(\"\\n--- Pre-Training Validation ---\")\n",
                "!python pre_training_validation.py"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Training\n",
                "Running the main training loop."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# GPU Validation\n",
                "!nvidia-smi\n",
                "\n",
                "# Clear previous logs if needed\n",
                "# !rm -rf logs/\n",
                "\n",
                "# Run training\n",
                "!python scripts/train.py"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Artifact Archival\n",
                "Zip results for download."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import shutil\n",
                "from datetime import datetime\n",
                "\n",
                "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
                "archive_name = f\"training_artifacts_{timestamp}\"\n",
                "\n",
                "print(\"Archiving checkpoints and logs...\")\n",
                "shutil.make_archive(archive_name, 'zip', root_dir='.', base_dir='checkpoints')\n",
                "shutil.make_archive(f\"{archive_name}_logs\", 'zip', root_dir='.', base_dir='logs')\n",
                "\n",
                "print(f\"Created {archive_name}.zip and {archive_name}_logs.zip\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}